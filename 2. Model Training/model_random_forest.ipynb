{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Model Optimised\n",
    "- Uses ensemble of decision trees.\n",
    "- Breaking whole bunch of decision trees and putting them together.\n",
    "- Increases prediction accuracy  \n",
    "PRO   \n",
    "- Reduces over fitting - which may not be representative of true population\n",
    "- Reduces Bias - i.e. not evenly split in training.\n",
    "\n",
    "The number of estimators - number of decision trees used to build the ensemble model. \n",
    "In order for the sampling techniques to work best, you should previously perform any pre-processing steps you can. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1.  Import Dependancies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, learning_curve\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, average_precision_score\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read in CSV - Test with Option 2 for Sampling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### OPTION 1 if NOT SAMPLING DATA\n",
    "#################################################\n",
    "# READ IN CSV fraud_det_dig_df\n",
    "fraud_df = pd.read_csv(\"../Resources/fraud_det_dig_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######## OPTION 2 for SAMPLING DATA\n",
    "########################################################\n",
    "# ## Create additional step if SAMPLING only.\n",
    "# ## READ IN CSV fraud_det_dig_df\n",
    "# fraud_det_df = pd.read_csv(\"../Resources/fraud_det_dig_df.csv\")\n",
    "# fraud_det_df.head()\n",
    "\n",
    "# ## Create Sample of data to work with\n",
    "# # Determine the proportions of 'isFraud' values in the DataFrame\n",
    "# fraud_proportions = fraud_det_df['isFraud'].value_counts(normalize=True)\n",
    "\n",
    "# # Calculate the number of samples needed for each 'isFraud' value\n",
    "# sample_size = 100000\n",
    "# sample_per_is_fraud = (fraud_proportions * sample_size).astype(int)\n",
    "\n",
    "# # Use the 'groupby' function to take a proportional sample\n",
    "# fraud_df = fraud_det_df.groupby('isFraud').apply(lambda x: x.sample(sample_per_is_fraud[x.name]))\n",
    "\n",
    "# # Reset the index of the sampled DataFrame\n",
    "# fraud_df.reset_index(drop=True, inplace=True)\n",
    "# fraud_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Set Up Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target vector and features\n",
    "y = fraud_df['isFraud'].values.reshape(-1, 1)\n",
    "\n",
    "# iterations of the model identified to drop the following features\n",
    "X = fraud_df.drop(['isFraud','isFlaggedFraud','large_transaction','newbalanceOrig','week','bal_change_per'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform train-test split on the original DataFrame\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling Data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "# UNDERSAMPLING using RandomUndersampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_rus, y_rus = rus.fit_resample(X_train_scaled, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of 'isFraud' before balancing\n",
    "plt.figure(figsize=(5, 4))\n",
    "ax = sns.countplot(data=fraud_df, x='isFraud', palette={0: 'lightblue', 1: 'darkred'})\n",
    "\n",
    "for p in ax.patches:\n",
    "    count = p.get_height()\n",
    "    ax.annotate(f\"{count:.0f}\", (p.get_x() + p.get_width() / 2., count),\n",
    "                ha='center', va='center', fontsize=8, color='black', xytext=(0, 3), textcoords='offset points')\n",
    "\n",
    "plt.title(\"Distribution of Fraudulent Transactions (Before Balancing)\")\n",
    "plt.xlabel(\"isFraud\")\n",
    "plt.ylabel(\"Count (Millions)\")\n",
    "plt.show()\n",
    "\n",
    "# Visualize the distribution of 'isFraud' after Random Undersampling\n",
    "plt.figure(figsize=(5, 4))\n",
    "ax = sns.countplot(x=y_rus, palette={0: 'lightblue', 1: 'darkred'})\n",
    "\n",
    "for p in ax.patches:\n",
    "    count = p.get_height()\n",
    "    ax.annotate(f\"{count:.0f}\", (p.get_x() + p.get_width() / 2., count),\n",
    "                ha='center', va='center', fontsize=8, color='black', xytext=(0, 3), textcoords='offset points')\n",
    "\n",
    "plt.title(\"Distribution of Fraudulent Transactions (After Random Undersampling)\")\n",
    "plt.xlabel(\"isFraud\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------------------------------\n",
    "### Part 3.  Fitting the Random Forest Model\n",
    "-----------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a random forest classifier\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=78)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model on the resampled data\n",
    "rf_model.fit(X_rus, y_rus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Making Preductions Using Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making predictions using the testing data\n",
    "predictions = rf_model.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Evaluation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"], columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "cm\n",
    "\n",
    "# Calculating the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "\n",
    "## create Classification Report as a dataframe\n",
    "report_dict = classification_report(y_test, predictions, output_dict=True)\n",
    "classification_report_df = pd.DataFrame(report_dict).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displaying results\n",
    "print(\"Confusion Matrix\")\n",
    "display(cm_df)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n",
    "print(\"--------------------\")\n",
    "print(\"Classification Report\")\n",
    "classification_report_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print Model evaluation to CSV for Tableau\n",
    "\n",
    "cm_df.to_csv('../Resources/confusion_matrix.csv', index=False)\n",
    "classification_report_df.to_csv('../Resources/classification_report.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the feature importance array\n",
    "importances = rf_model.feature_importances_\n",
    "# List the top 10 most important features\n",
    "importances_sorted = sorted(zip(rf_model.feature_importances_, X.columns), reverse=True)\n",
    "importances_sorted[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with feature importances\n",
    "importances_df = pd.DataFrame({'Feature': X.columns, 'Importance': rf_model.feature_importances_})\n",
    "\n",
    "# Sort the DataFrame by importance values in ascending order to rank features from top to bottom\n",
    "importances_sorted = importances_df.sort_values(by='Importance')\n",
    "\n",
    "# Plot the feature importances with dark red color scheme\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importances_sorted['Feature'], importances_sorted['Importance'], color='darkred')\n",
    "plt.title('Feature Importances')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Convert importances_sorted to a DataFrame then print for Tableau\n",
    "importances_df = pd.DataFrame(importances_sorted, columns=['weighting', 'feature'])\n",
    "\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "importances_df.to_csv('../Resources/importance_sorted.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Save my rf_model as pickle file\n",
    "model = rf_model\n",
    "\n",
    "# Specify the filename for the pickle file\n",
    "filename = 'model.pkl'\n",
    "\n",
    "# Save the model to the pickle file\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(model, file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optimisation of Model\n",
    "Finding the optimal n_estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "######\n",
    "###################################\n",
    "# Define target vector and features\n",
    "y = fraud_df['isFraud'].values.reshape(-1, 1)\n",
    "X = fraud_df.drop('isFraud', axis=1)\n",
    "\n",
    "# Perform train-test split on the original DataFrame\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scaling Data using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# UNDERSAMPLING using RandomUndersampler\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "X_rus, y_rus = rus.fit_resample(X_train_scaled, y_train.ravel())\n",
    "\n",
    "# Define a range of values for n_estimators to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400, 500]\n",
    "}\n",
    "\n",
    "# Create a random forest classifier\n",
    "rf_model = RandomForestClassifier(random_state=78)\n",
    "\n",
    "# Perform GridSearchCV with 5-fold cross-validation to find the best n_estimators value\n",
    "grid_search = GridSearchCV(rf_model, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_rus, y_rus)\n",
    "\n",
    "# Get the best n_estimators value from the grid search results\n",
    "best_n_estimators = grid_search.best_params_['n_estimators']\n",
    "print(\"Best n_estimators:\", best_n_estimators)\n",
    "\n",
    "# Train the model with the best n_estimators value on the full training set\n",
    "best_rf_model = RandomForestClassifier(n_estimators=best_n_estimators, random_state=78)\n",
    "best_rf_model.fit(X_rus, y_rus)\n",
    "\n",
    "# Making predictions using the testing data\n",
    "predictions = best_rf_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculating the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy Score:\", acc_score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
